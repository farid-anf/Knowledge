# Statistics: 
In statistical hypothesis testing, Type I and Type II errors are potential mistakes that can occur when making decisions based on sample data.

# Type I and Type II Error: 

### Type I Error (False Positive)
- **Definition:** A Type I error occurs when the null hypothesis \( H_0 \) is true, but it is incorrectly rejected.
- **Significance Level (α):** The probability of committing a Type I error is denoted by α. This is the level of significance set by the researcher (e.g., 0.05), which represents a 5% risk of rejecting the null hypothesis when it is actually true.
- **Example:** If you are testing a new drug to determine if it has a significant effect, a Type I error would occur if you conclude that the drug works (reject the null hypothesis) when in fact it does not.

### Type II Error (False Negative)
- **Definition:** A Type II error occurs when the null hypothesis \( H_0 \) is false, but it is incorrectly accepted (failed to be rejected).
- **Beta (β):** The probability of committing a Type II error is denoted by β. This probability depends on the power of the test, which is the likelihood that the test correctly rejects a false null hypothesis.
- **Power (1 - β):** The power of a test is the probability that it correctly rejects the null hypothesis when it is false. Higher power means a lower probability of Type II error.
- **Example:** Continuing with the drug example, a Type II error would occur if you conclude that the drug does not work (fail to reject the null hypothesis) when in fact it does.

### Summary of Differences
- **Type I Error (α):** Rejecting a true null hypothesis (false positive).
- **Type II Error (β):** Failing to reject a false null hypothesis (false negative).
- **Control:** Type I error is controlled by setting a significance level (α), while Type II error is controlled by increasing the sample size, effect size, or power of the test.
- **Consequences:** The consequences of these errors depend on the context. Type I errors can lead to believing there is an effect when there isn't, while Type II errors can lead to missing out on a real effect.

In practical terms, researchers must balance the risks of both errors depending on the situation and the consequences of making incorrect decisions.
